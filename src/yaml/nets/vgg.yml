learning_rate: 0.02
weight_decay: 0.00001 # ADAM decay
color_channels: 3
supervised_ratio: 0.05
batch_size: 1000
test_every_n_epochs: 10
pred_loss_weight: 0.3

# must be configured in env.yml 
dataset: cifar10 # Supports mnist|cifar10
decoding_criterion: MSELoss # Supports: MSELoss
prediction_criterion: CrossEntropyLoss # Supports: CrossEntropyLoss

# pretraining_store must be a path !
# pretraining_load must be a file name !
layers:
  - num_epoch: 50
    dropout_rate: 0.3
    model: VGGn # VGG n-th layer
    optimizer: Adam
    # pretraining_load: trained_models/cifar10/layer_0_stack.pickle
    # pretraining_store: null
    pretraining_load: null 
    pretraining_store: trained_models/cifar10 
    upstream_params: null

  - num_epoch: 50
    dropout_rate: 0.3
    model: VGGn # VGG n-th layer
    optimizer: Adam
    pretraining_load:  null
    pretraining_store: trained_models/cifar10 
    upstream_params: null
